{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# things we need for NLP\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# things we need for Tensorflow\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pruthvi', 'bangalore']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# NER - Getting named entities \n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import nltk\n",
    "import nltk.collocations\n",
    "import nltk.corpus\n",
    "\n",
    "word_list = word_tokenize(open('words.txt').read())\n",
    "punctuations = ['^', ')', '/', '#', '{', '=','-', '~', '|', '`', '&', '$', '_', ',', '\\\\', '?', \"'\", '[', '(', ']', '*', '\"', ':', '}', '%', '<', '.', '>', '!', '@', '+', ';']\n",
    "\n",
    "def processLanguage(text):\n",
    "    new_sent =[]\n",
    "    for t in text:\n",
    "        if t not in punctuations:\n",
    "            new_sent.append(t)\n",
    "        elif t in punctuations:\n",
    "            new_sent.append(' ')\n",
    "            new_sent.append(t)\n",
    "            new_sent.append(' ')\n",
    "    new_sent = ''.join(new_sent)\n",
    "    sentences = sent_tokenize(new_sent)\n",
    "    \n",
    "    try:\n",
    "        proper_nouns =[]\n",
    "        for item in sentences:\n",
    "            l = word_tokenize(item.lower())\n",
    "            s = re.compile(r'\\.')\n",
    "            p = s.sub(r' . ',' '.join(l))\n",
    "            words = word_tokenize(p)\n",
    "            for i in range(len(words)):\n",
    "                if words[i] not in word_list:\n",
    "                    words[i] = words[i].capitalize()\n",
    "                    #print(words[i].capitalize())\n",
    "            item = ' '.join(words)\n",
    "            tokenized = nltk.word_tokenize(item)\n",
    "            tagged = nltk.pos_tag(tokenized)\n",
    "            #print tagged\n",
    "            namedEnt = nltk.ne_chunk(tagged)\n",
    "            #namedEnt.draw()\n",
    "            #print(namedEnt)\n",
    "            for ent in namedEnt:    \n",
    "                if type(ent)==nltk.tree.Tree:\n",
    "                    if type(ent[0]) == tuple:\n",
    "                        #print(ent[0][0])\n",
    "                        proper_nouns.append(ent[0][0])\n",
    "                #print(ent[0])\n",
    "        return [i.lower() for i in proper_nouns]\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "processLanguage(\"I am Pruthvi . I live in Bangalore .\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import our chat-bot intents file\n",
    "import json\n",
    "with open('new_intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272 documents\n",
      "8 classes ['district', 'goodbye', 'greeting', 'no reply', 'thanks', 'time', 'want to donate', 'want to receive']\n",
      "168 unique stemmed words ['!', \"'m\", \"'s\", '*', '*blood_group*', '*district_name*', '*time', '*time*', ',', '.', 'a', 'about', 'aft', 'afternoon', 'alright', 'am', 'any', 'anyon', 'apprecy', 'ar', 'as', 'aunt', 'be', 'been', 'bef', 'blood', 'by', 'bye', 'camp', 'can', 'car', 'catch', 'check', 'clos', 'com', 'could', 'daught', 'day', 'dear', 'deposit', 'detail', 'district', 'do', 'doing', 'don', 'dur', 'ev', 'everyth', 'farewel', 'fath', 'fin', 'find', 'for', 'from', 'funct', 'get', 'giv', 'go', 'going', 'good', 'goodby', 'goodnight', 'got', 'gre', 'hav', 'head', 'hello', 'help', 'her', 'hey', 'hi', 'hiy', 'hmm', 'hospit', 'hour', 'how', 'husband', 'i', 'if', 'immedy', 'in', 'inform', 'intend', 'is', 'it', 'know', 'lat', 'lif', 'lik', 'loc', 'long', 'lot', 'lov', 'm', 'man', 'many', 'meet', 'mor', 'morn', 'moth', 'much', 'my', 'nee', 'nic', 'night', 'of', 'off', 'oh', 'ok', 'okay', 'on', 'op', 'or', 'out', 'plac', 'pleas', 'real', 'receiv', 'rel', 'run', 's', 'see', 'serv', 'should', 'so', 'som', 'son', 'soon', 'start', 'sup', 'ta', 'tak', 'talk', 'thank', 'that', 'the', 'then', 'ther', 'thi', 'thing', 'tim', 'to', 'unc', 'understand', 'until', 'up', 'urg', 'us', 'very', 'visit', 'want', 'we', 'wel', 'wer', 'what', 'whazzup', 'when', 'wher', 'which', 'wif', 'wil', 'wish', 'work', 'would', 'yeah', 'yo', 'you', 'â€™']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?']\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        # add to documents in our corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# remove duplicates\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "print (len(classes), \"classes\", classes)\n",
    "print (len(words), \"unique stemmed words\", words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "output = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # stem each word\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])\n",
    "    \n",
    "\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "#print(training[:,1])\n",
    "\n",
    "# create train and test lists\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 329999  | total loss: \u001b[1m\u001b[32m0.05298\u001b[0m\u001b[0m | time: 0.092s\n",
      "| Adam | epoch: 10000 | loss: 0.05298 - acc: 0.9942 -- iter: 256/261\n",
      "Training Step: 330000  | total loss: \u001b[1m\u001b[32m0.04828\u001b[0m\u001b[0m | time: 0.095s\n",
      "| Adam | epoch: 10000 | loss: 0.04828 - acc: 0.9948 -- iter: 261/261\n",
      "--\n",
      "INFO:tensorflow:/home/pruthvi/Desktop/Thought_Clan/blood_bank_querybot/model.table_tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    # reset underlying graph data\n",
    "    tf.reset_default_graph()\n",
    "    # Build neural network\n",
    "    table_net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "    table_net = tflearn.fully_connected(table_net, 8)\n",
    "    table_net = tflearn.fully_connected(table_net, 8)\n",
    "    table_net = tflearn.fully_connected(table_net, len(train_y[0]), activation='softmax')\n",
    "    table_net = tflearn.regression(table_net)\n",
    "    # Define model and setup tensorboard\n",
    "    model = tflearn.DNN(table_net, tensorboard_dir='table_tflearn_logs')\n",
    "    # Start training (apply gradient descent algorithm)\n",
    "    model.fit(train_x, train_y, n_epoch=10000, batch_size=8, show_metric=True)\n",
    "    model.save('model.table_tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save all of our data structures\n",
    "import pickle\n",
    "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"training_data\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/pruthvi/Desktop/Thought_Clan/blood_bank_querybot/model.table_tflearn\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "table_net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "table_net = tflearn.fully_connected(table_net, 8)\n",
    "table_net = tflearn.fully_connected(table_net, 8)\n",
    "table_net = tflearn.fully_connected(table_net, len(train_y[0]), activation='softmax')\n",
    "table_net = tflearn.regression(table_net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(table_net, tensorboard_dir='table_tflearn_logs')\n",
    "\n",
    "# restore all of our data structures\n",
    "import pickle\n",
    "data = pickle.load( open( \"training_data\", \"rb\" ) )\n",
    "words = data['words']\n",
    "classes = data['classes']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n",
    "\n",
    "# import our chat-bot intents file\n",
    "import json\n",
    "with open('new_intents.json') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "    \n",
    "# load our saved model\n",
    "model.load('./model.table_tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a data structure to hold user context\n",
    "context = {}\n",
    "\n",
    "ERROR_THRESHOLD = 0.25\n",
    "def classify(sentence):\n",
    "    # generate probabilities from the model\n",
    "    results = model.predict([bow(sentence, words)])[0]\n",
    "    # filter out predictions below a threshold\n",
    "    \n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    #results = [[i,r] for i,r in enumerate(results)]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1]))\n",
    "    # return tuple of intent and probability\n",
    "    return return_list\n",
    "\n",
    "\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    results = [i[0] for i in results]\n",
    "    #results = multi_intent(sentence)\n",
    "    # if we have a classification then find the matching intent tag\n",
    "    if results:\n",
    "        # loop as long as there are matches to process\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # find a tag matching the first result\n",
    "                if i['tag'] == results[0]:\n",
    "                    # set context for this intent if necessary\n",
    "                    if 'context_set' in i:\n",
    "                        if show_details: print('context:', i['context_set'])\n",
    "                        context[userID] = i['context_set']\n",
    "\n",
    "                    # check if this intent is contextual and applies to this user's conversation\n",
    "                    if not 'context_filter' in i or \\\n",
    "                        (userID in context and 'context_filter' in i and context[userID] in i['context_filter']):\n",
    "                        if show_details: print ('tag:', i['tag'])\n",
    "                        # a random response from the intent\n",
    "                        return i['function']\n",
    "                    else:\n",
    "                        return \"context_not_set_handler\"\n",
    "            results.pop(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_intent(query):\n",
    "    res = [i[0] for i in classify(query)]\n",
    "    #print(res)\n",
    "    if(len(res)>1):\n",
    "        #print(res)\n",
    "        print(\"Multiple intents found\")\n",
    "        return res\n",
    "    else:\n",
    "        sentences = sent_tokenize(query)\n",
    "        #print(sentences)\n",
    "        if(len(sentences)>1):\n",
    "            intents = []\n",
    "            for i in sentences:\n",
    "                #print(classify(i))\n",
    "                sub_intents = classify(i)\n",
    "                for j in sub_intents:\n",
    "                    intents.append(j[0])\n",
    "            #print(intents)\n",
    "            intents = list(set(intents))\n",
    "            if('time' in intents):\n",
    "                intents.remove('time')\n",
    "                intents.append('time')\n",
    "            elif('greeting' in intents):\n",
    "                intents.remove('greeting')\n",
    "                intents = ['greeting']+intents\n",
    "            return intents\n",
    "        else:\n",
    "            words = word_tokenize(query)\n",
    "            sentences = [' '.join(words[:int(len(words)/2)]),' '.join(words[int(len(words)/2):])]\n",
    "            #print(sentences)\n",
    "            intents = []\n",
    "            for i in sentences:\n",
    "                #print(classify(i))\n",
    "                sub_intents = classify(i)\n",
    "                for j in sub_intents:\n",
    "                    if(j[1]>0.5):\n",
    "                        intents.append(j[0])\n",
    "            #print(intents)\n",
    "            intents = list(set(intents))\n",
    "            if('time' in intents):\n",
    "                intents.remove('time')\n",
    "                intents.append('time')\n",
    "            elif('greeting' in intents):\n",
    "                intents.remove('greeting')\n",
    "                intents = ['greeting']+intents\n",
    "            return intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "#connecting to database\n",
    "conn=sql.connect(\"blood.db\")\n",
    "\n",
    "def capture_context(user_chat_history):\n",
    "    for i in user_chat_history:\n",
    "        result = classify(i)[0][0]\n",
    "        print(i,end = \"-->\")\n",
    "        print(result)\n",
    "        #print()\n",
    "\n",
    "\n",
    "\n",
    "tables = ['district','bill_payment','blood_recepient','donor','hospital']\n",
    "\n",
    "def district_handler(query):\n",
    "    result = classify(query)[0][0]\n",
    "    b_grp = ['a+','a-','b+','b-','ab+','ab-','o+','o-']\n",
    "    w = [i.lower() for i in word_tokenize(query)]\n",
    "    blood_group = [i for i in w if i in b_grp]\n",
    "    #print(blood_group)\n",
    "    if(len(blood_group)>0):\n",
    "        query = query.lower()\n",
    "        query = query.split(' ')\n",
    "        for i in query:\n",
    "            if blood_group[0] in i:\n",
    "                query.remove(i)\n",
    "\n",
    "        query = ' '.join(query)\n",
    "        blood_group = blood_group[0]\n",
    "    #print(query)\n",
    "    else:\n",
    "        blood_group = None\n",
    "    details = dict()\n",
    "    details['table'] = \"district\"\n",
    "    details['named_entities'] = processLanguage(query)\n",
    "    if(len(details['named_entities'])==0):\n",
    "        command = \"select dname from district;\"\n",
    "        res = list(conn.execute(command))\n",
    "        #[('kurnool',), ('chitoor',), ('anantapur',), ('kadapa',), ('guntur',)]\n",
    "        l = [\"We operate in \\n\",\"We have our camps in the following districts\\n\",\"You can visit the closest among the following districts\\n\"]\n",
    "        s = random.choice(l)\n",
    "        for i in res:\n",
    "            s = s + i[0]+\"\\n\"\n",
    "        return s\n",
    "    l = []\n",
    "    #implement a classifier to indentify if a query is of boolean , select or aggregate type\n",
    "    #assuming the type of query is a boolean query\n",
    "    for i in details['named_entities']:\n",
    "        #print(i)\n",
    "        #have to identify the column/columns in target\n",
    "        #print(i)\n",
    "        command = \"select * from \"+ details['table'] +\" where dname= '\"+i+\"';\"\n",
    "        #print(command)\n",
    "        res = list(conn.execute(command))\n",
    "        #print(res)\n",
    "        conn.commit()\n",
    "        if(len(res)>0):\n",
    "            l.append(\"Yes\")\n",
    "        else:\n",
    "            l.append(\"No\")\n",
    "    if(len(l)>0):\n",
    "        return l[0]\n",
    "    else:\n",
    "        return \"Yet to resolve this query\"\n",
    "\n",
    "\n",
    "'''\n",
    "def get_ent(query):\n",
    "    nlp2 = spacy.load(\"/home/pruthvi/Desktop/Thought_Clan/blood_bank_querybot/my_ner\")\n",
    "    s = query.lower()\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    doc = nlp2(s)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    for i in entities:\n",
    "        if(i[0] in stop_words):\n",
    "            entities.remove(i)\n",
    "    \n",
    "    ents = [i[0] for i in entities]\n",
    "    named_ents = processLanguage(query)\n",
    "    \n",
    "    place = []\n",
    "    for i in named_ents:\n",
    "        for j in ents:\n",
    "            if(i in j):\n",
    "                place.append(i)\n",
    "            \n",
    "    print(entities,place)\n",
    "'''\n",
    "\n",
    "\n",
    "def get_ent(query,donor=False,recepient=False):\n",
    "    b_grp = ['a+','a-','b+','b-','ab+','ab-','o+','o-']\n",
    "    w = [i.lower() for i in word_tokenize(query)]\n",
    "    blood_group = [i for i in w if i in b_grp]\n",
    "    #print(blood_group)\n",
    "    if(len(blood_group)>0):\n",
    "        query = query.lower()\n",
    "        query = query.split(' ')\n",
    "        for i in query:\n",
    "            if blood_group[0] in i:\n",
    "                query.remove(i)\n",
    "\n",
    "        query = ' '.join(query)\n",
    "        blood_group = blood_group[0]\n",
    "    #print(query)\n",
    "    else:\n",
    "        blood_group = None\n",
    "    named_ents = processLanguage(query)\n",
    "    #print(named_ents)\n",
    "    if(len(named_ents)>0):\n",
    "        location = named_ents[0]\n",
    "    else:\n",
    "        location = None\n",
    "    units = re.findall(r'\\d+', query)\n",
    "    units = [int(i) for i in units]\n",
    "    if(len(units)>1):\n",
    "        unit = min(units)\n",
    "        age = max(units)\n",
    "    elif(len(units)==1):\n",
    "        if(units[0]<10):\n",
    "            unit = units[0]\n",
    "            age = None\n",
    "        else:\n",
    "            unit = None\n",
    "            age = units[0]\n",
    "    else:\n",
    "        unit = None\n",
    "        age = None\n",
    "    #if(units!=None):\n",
    "    #    units = units.group()\n",
    "    #print(units)\n",
    "    \n",
    "    if(donor==True):\n",
    "        ent_dict = {'age':age,'blood_group':blood_group,'location':location}\n",
    "        return ent_dict\n",
    "    elif(recepient==True):\n",
    "        ent_dict = {'age':age,'blood_group':blood_group,'location':location,'units_required':unit}\n",
    "        return ent_dict    \n",
    "\n",
    "    \n",
    "\n",
    "def context_not_set_handler(query):\n",
    "    return \"Will have to set context before asking this ...\"\n",
    "    \n",
    "def greeting_handler(query):\n",
    "    l = [\"Hello, thanks for visiting\", \"Good to see you again\", \"Hi there, how can I help?\"]\n",
    "    return random.choice(l)\n",
    "    \n",
    "def goodbye_handler(query):\n",
    "    l = [\"See you later, thanks for visiting\", \"Have a nice day\", \"Bye! Come back again soon.\"]\n",
    "    return random.choice(l)\n",
    "    \n",
    "def thanks_handler(query):\n",
    "    l = [\"Happy to help!\", \"Any time!\", \"My pleasure\"]\n",
    "    return random.choice(l)\n",
    "\n",
    "def time_handler(query):\n",
    "    l = [\"The camps in the hospitals open at 9AM and close by 11PM .\"]\n",
    "    return random.choice(l)\n",
    "\n",
    "def want2donate_handler(query):\n",
    "    l = [\"Glad to hear that.\",\"Good to know.\",\"Pleased to hear that\"]\n",
    "    print(\"bot reply - \"+random.choice(l)+\"\\nI might need a few more details\")\n",
    "    questions = dict()\n",
    "    donor_details = dict()\n",
    "    questions['age'] = ['How old are you ?','May I know your age ?','What is your age ?']\n",
    "    questions['blood_group'] = ['What is your blood group ?',\"May I know your blood group ?\"]\n",
    "    questions['location'] = ['Name the city/town you live in .','Which city do you stay ?',\"Where do you live ?\",\"Please tell me your place of stay.\"]\n",
    "    \n",
    "    donor_details['age'] =[]\n",
    "    donor_details['blood_group'] = []\n",
    "    donor_details['location'] =[]\n",
    "    \n",
    "    ent_dict = get_ent(query,donor=True)\n",
    "    for i in ent_dict.keys():\n",
    "        if(ent_dict[i]!=None):\n",
    "            donor_details[i].append(ent_dict[i])\n",
    "    \n",
    "    b_grp = ['a+','a-','b+','b-','ab+','ab-','o+','o-']\n",
    "    \n",
    "    while(len(donor_details['age'])==0 or len(donor_details['blood_group'])==0 or len(donor_details['location'])==0):\n",
    "        a = random.choice(list(donor_details.keys()))\n",
    "        if(len(donor_details[a])==0):\n",
    "            print(random.choice(questions[a]))\n",
    "            if(a=='age'):\n",
    "                try:\n",
    "                    donor_details['age'].append(int(input()))\n",
    "                except:\n",
    "                    print(\"Please enter valid age\")\n",
    "                    while(True):\n",
    "                        try:\n",
    "                            donor_details['age'].append(int(input()))\n",
    "                            break\n",
    "                        except:\n",
    "                            print(\"Please enter valid age\")\n",
    "                            \n",
    "            elif(a=='blood_group'):\n",
    "                while(True):\n",
    "                    w = [i.lower() for i in word_tokenize(input())]\n",
    "                    bl_grp = [i for i in w if i in b_grp]\n",
    "                    if(len(bl_grp)>0):\n",
    "                        donor_details['blood_group'].append(bl_grp[0])\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Please enter valid blood group\")\n",
    "            elif(a=='location'):\n",
    "                while(True):\n",
    "                    w = processLanguage(input())\n",
    "                    if(len(w)>0):\n",
    "                        donor_details['location'].append(w[0])\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Please enter a valid location\")\n",
    "                    \n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    print(\"Here are your details:\")\n",
    "    for i in list(donor_details.keys()):\n",
    "        print( i ,\":\", donor_details[i][0])\n",
    "    \n",
    "    if(donor_details['age'][0]<=50):\n",
    "        print(\"We would be drawing a maximum of 2 units of blood (350ml) from you .\")\n",
    "    else:\n",
    "        print(\"We would be drawing a unit of blood (350 ml) from you .\")\n",
    "    districts = [\"Kurnool\" , \"Guntur\" , \"Kadapa\" , \"Chitoor\",\"Anantapur\"]\n",
    "    dis = random.choice(districts)\n",
    "    print(dis+\" should be the closest to your place.\")\n",
    "    \n",
    "    print(\"Please visit any government hospital in \"+dis+\" district to donate blood\")\n",
    "    print(\"We appreciate your willingness . Thank you\")\n",
    "    return ''\n",
    "\n",
    "def want2receive_handler(query):\n",
    "    l = [\"Okay\",\"I see\",\"Sure\",\"Oh okay\",\"Oh\"]\n",
    "    print(\"bot reply - \"+random.choice(l)+\"\\nI might need a few more details\")\n",
    "    questions = dict()\n",
    "    recepient_details = dict()\n",
    "    questions['age'] = ['How old are you ?','May I know your age ?','What is your age ?']\n",
    "    questions['blood_group'] = ['What is your blood group ?',\"May I know your blood group ?\"]\n",
    "    questions['location'] = ['Name the city/town you live in .','Which city do you stay ?',\"Where do you live ?\",\"Please tell me your place of stay.\"]\n",
    "    questions['units_required'] = ['How many units of blood do you want ?','How many units of blood are required ?','How many units do you want ?',\"What's the quantity in need (in terms of units)?\"]\n",
    "    \n",
    "    recepient_details['age'] =[]\n",
    "    recepient_details['blood_group'] = []\n",
    "    recepient_details['location'] =[]\n",
    "    recepient_details['units_required'] = []\n",
    "    \n",
    "    ent_dict = get_ent(query,recepient=True)\n",
    "    for i in ent_dict.keys():\n",
    "        if(ent_dict[i]!=None):\n",
    "            recepient_details[i].append(ent_dict[i])\n",
    "    \n",
    "    b_grp = ['a+','a-','b+','b-','ab+','ab-','o+','o-']\n",
    "    \n",
    "    while(len(recepient_details['age'])==0 or len(recepient_details['blood_group'])==0 or len(recepient_details['location'])==0 or len(recepient_details['units_required'])==0):\n",
    "        a = random.choice(list(recepient_details.keys()))\n",
    "        if(len(recepient_details[a])==0):\n",
    "            print(random.choice(questions[a]))\n",
    "            if(a=='age'):\n",
    "                try:\n",
    "                    recepient_details['age'].append(int(input()))\n",
    "                except:\n",
    "                    print(\"Please enter valid age\")\n",
    "                    while(True):\n",
    "                        try:\n",
    "                            recepient_details['age'].append(int(input()))\n",
    "                            break\n",
    "                        except:\n",
    "                            print(\"Please enter valid age\")\n",
    "            elif(a=='blood_group'):\n",
    "                while(True):\n",
    "                    w = [i.lower() for i in word_tokenize(input())]\n",
    "                    bl_grp = [i for i in w if i in b_grp]\n",
    "                    if(len(bl_grp)>0):\n",
    "                        recepient_details['blood_group'].append(bl_grp[0])\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Please enter valid blood group\")\n",
    "                    \n",
    "            elif(a=='location'):\n",
    "                while(True):\n",
    "                    w = processLanguage(input())\n",
    "                    if(len(w)>0):\n",
    "                        recepient_details['location'].append(w[0])\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Please enter a valid location\")\n",
    "                    \n",
    "            elif(a=='units_required'):\n",
    "                try:\n",
    "                    recepient_details['units_required'].append(int(input()))\n",
    "                except:\n",
    "                    print(\"Please enter a number\")\n",
    "                    while(True):\n",
    "                        try:\n",
    "                            recepient_details['units_required'].append(int(input()))\n",
    "                            break\n",
    "                        except:\n",
    "                            print(\"Please enter a number\")\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    print(\"Here are your details:\")\n",
    "    for i in list(recepient_details.keys()):\n",
    "        print( i ,\":\", recepient_details[i][0])\n",
    "    \n",
    "    \n",
    "    districts = [\"Kurnool\" , \"Guntur\" , \"Kadapa\" , \"Chitoor\",\"Anantapur\"]\n",
    "    #dis = random.choice(districts)\n",
    "    #print(dis+\" should be the closest to your place.\")\n",
    "    \n",
    "    for dis in districts:\n",
    "        command = \"select dis_id from district where dname='\"+dis.lower()+\"';\"\n",
    "        did = list(conn.execute(command))[0][0][1]\n",
    "        conn.commit()\n",
    "        \n",
    "        command = \"select hname,hb_qty,h_id from hospital where dis_id = '\"+did+\"' and hb_grp='\"+recepient_details['blood_group'][0].upper()+\"';\"\n",
    "        b_qty = list(conn.execute(command))[0][1]\n",
    "        hname =list(conn.execute(command))[0][0]\n",
    "        h_id =list(conn.execute(command))[0][2]\n",
    "        if(int(b_qty)>=int(recepient_details['units_required'][0])):\n",
    "            print(\"Requirement found at hospital \",hname,\"in\",dis,\"district \")\n",
    "            print(\"You might be charged \",100*recepient_details['units_required'][0])\n",
    "            print(\"Please visit the hospital \")\n",
    "            print(\"Hope we have helped . Thank you\")\n",
    "            \n",
    "            #command = \"update hospital set hb_qty=\"+str(b_qty-int(recepient_details['units_required'][0]))+\" where h_id ='\"+str(h_id)+\"' and hb_grp ='\"+recepient_details['blood_group'][0].upper()+\"';\"                           \n",
    "            \n",
    "            \n",
    "            return ''\n",
    "    \n",
    "    print(\"Couldn't find requirement . Extremely sorry\")\n",
    "    return ''\n",
    "\n",
    "def no_reply_handler(query):\n",
    "    return '...'\n",
    "\n",
    "def chat():\n",
    "    user_chat_history = []\n",
    "    bot_chat_history = []\n",
    "    print(\"Hello there !\")\n",
    "    query = \"\"\n",
    "    while(classify(query)[0][0]!='goodbye'):\n",
    "        query = input()\n",
    "        user_chat_history.append(query)\n",
    "        #s = response(query,show_details=True)\n",
    "        s = response(query)\n",
    "        #print(s)\n",
    "        reply = globals()[s](query)\n",
    "        '''\n",
    "        if(s in tables):\n",
    "            #reply = db_action(query,s)\n",
    "            reply = globals()[s+\"_handler\"](query,s)\n",
    "        else:\n",
    "            reply = s\n",
    "        '''\n",
    "        bot_chat_history.append(reply)\n",
    "        print(\"bot reply - \",reply)\n",
    "        print()\n",
    "    #capture_context(user_chat_history)\n",
    "    #return (user_chat_history,bot_chat_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there !\n",
      "hey\n",
      "bot reply -  Good to see you again\n",
      "\n",
      "I want to donate blood\n",
      "bot reply - Pleased to hear that\n",
      "I might need a few more details\n",
      "May I know your age ?\n",
      "13\n",
      "What is your blood group ?\n",
      "O-\n",
      "Where do you live ?\n",
      "jamshedpur\n",
      "Here are your details:\n",
      "age : 13\n",
      "blood_group : o-\n",
      "location : jamshedpur\n",
      "We would be drawing a maximum of 2 units of blood (350ml) from you .\n",
      "Anantapur should be the closest to your place.\n",
      "Please visit any government hospital in Anantapur district to donate blood\n",
      "We appreciate your willingness . Thank you\n",
      "bot reply -  \n",
      "\n",
      "vye\n",
      "bot reply -  No\n",
      "\n",
      "bye\n",
      "bot reply -  Bye! Come back again soon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = {}\n",
    "chat()\n",
    "\n",
    "#processLanguage(\"I am in Krishna district and I am looking for AB- blood group\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are in this function called sup\n"
     ]
    }
   ],
   "source": [
    "a = \"sup\"\n",
    "def sup():\n",
    "    print(\"You are in this function called sup\")\n",
    "    \n",
    "globals()[a]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag: thanks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'thanks_handler'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response(\"Where can I donate blood ?\",show_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('district', 0.8717994)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classify(\"how long are your camps open ?\")\n",
    "#classify()\"hey , i need some district info ?\")\n",
    "classify(\"i need some district information ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mysore']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processLanguage('Mysore is my home town')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donor_details = dict()\n",
    "\n",
    "donor_details['age'] =[]\n",
    "donor_details['blood_group'] = []\n",
    "donor_details['location'] =[]\n",
    "type(donor_details.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mysore', 'singapore', 'bangalore', 'mumbai']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#processLanguage(\"My name is Krishna and I want some blood and I live in gulbarga\")\n",
    "processLanguage(\"I come from New york and my name is Krishna\")\n",
    "#processLanguage(\"New york\")\n",
    "processLanguage('I have been to mysore,singapore,bangalore,mumbai and many other places')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['want to receive', 'want to donate']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multi_intent(query):\n",
    "    res = [i[0] for i in classify(query)]\n",
    "    #print(res)\n",
    "    if(len(res)>1):\n",
    "        #print(res)\n",
    "        print(\"Multiple intents found\")\n",
    "        return res\n",
    "    else:\n",
    "        sentences = sent_tokenize(query)\n",
    "        #print(sentences)\n",
    "        if(len(sentences)>1):\n",
    "            intents = []\n",
    "            for i in sentences:\n",
    "                #print(classify(i))\n",
    "                sub_intents = classify(i)\n",
    "                for j in sub_intents:\n",
    "                    intents.append(j[0])\n",
    "            #print(intents)\n",
    "            intents = list(set(intents))\n",
    "            if('time' in intents):\n",
    "                intents.remove('time')\n",
    "                intents.append('time')\n",
    "            elif('greeting' in intents):\n",
    "                intents.remove('greeting')\n",
    "                intents = ['greeting']+intents\n",
    "            return intents\n",
    "        else:\n",
    "            words = word_tokenize(query)\n",
    "            sentences = [' '.join(words[:int(len(words)/2)]),' '.join(words[int(len(words)/2):])]\n",
    "            if('' in sentences):\n",
    "                sentences.remove('')\n",
    "            #print(sentences)\n",
    "            intents = []\n",
    "            for i in sentences:\n",
    "                #print(classify(i))\n",
    "                sub_intents = classify(i)\n",
    "                for j in sub_intents:\n",
    "                    if(j[1]>0.5):\n",
    "                        intents.append(j[0])\n",
    "            #print(intents)\n",
    "            intents = list(set(intents))\n",
    "            if('time' in intents):\n",
    "                intents.remove('time')\n",
    "                intents.append('time')\n",
    "            elif('greeting' in intents):\n",
    "                intents.remove('greeting')\n",
    "                intents = ['greeting']+intents\n",
    "            return intents        \n",
    "\n",
    "\n",
    "#query = \"I want to donate blood.\"\n",
    "#query = \"Will the camps in Kurnool be open after 10PM ?\"\n",
    "#query = \"I live in Kurnool . I want to know if the camps will be open after 10PM .\"\n",
    "#query = \"Do the camps in kurnool open by 10AM\"\n",
    "#classify(query)\n",
    "query = \"Hello , I want to donate blood and I need blood as well\"\n",
    "multi_intent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('greeting', 0.9994491)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 98] Address already in use",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9dc715af3832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flask/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, host, port, debug, **options)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'use_debugger'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mrun_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# reset the first request information if the development server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36mrun_simple\u001b[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress_family\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOL_SOCKET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSO_REUSEADDR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_sockaddr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress_family\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set_inheritable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                 \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_inheritable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 98] Address already in use"
     ]
    }
   ],
   "source": [
    "#The Web UI part\n",
    "\n",
    "from flask import Flask,render_template ,redirect, url_for , request\n",
    "from flask_restful import reqparse, abort, Api, Resource\n",
    "\n",
    "app = Flask(__name__)\n",
    "api = Api(app)\n",
    "@app.route('/home')\n",
    "def home():\n",
    "    return render_template(\"homepage.html\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
